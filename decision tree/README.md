# 决策树算法实现

####简单做下总结 :
此算法对于连续特征和离散特征都适用。

如果是连续特征时，可以先进行离散化处理，再进行训练和预测,此算法进行的是二分离散,对于每个特征，计算它的所有特征值得信息增益，选择信息增益最大的特征值作为二分离散的阈值。

数据划分时的特征选择,实现时采用的时信息增益筛选。

在创建决策树时,结束递归的策略有两种:一是所有的类标签完全相同;二是使用完了所有特征,此时如果类标签还不完全相同,则采用多数表决的策略,返回出现次数最多的类标签;正常情况下这两个条件应该可以了,但是在实现过程中发现,如果离散化处理的不好,在建树后面可能出现特征没用完,但是该特征的值唯一且类标签不唯一,所以自己又添加了一个结束递归的条件。

代码结构处理的不太好,模型代码未单独分装,连续特征的离散化合测试也都应该单独处理。